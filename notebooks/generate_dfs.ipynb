{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process all lmbd datasets to Pandas Dataframes\n",
    "\n",
    "Information currently stored in Dataframes: \n",
    "\n",
    "- Adsorbate: formula, interneal index\n",
    "- Bulk: SLICES, Materials Project database identifier (mpid), formula, internal index\n",
    "- Surface: *hkl* Miller indices\n",
    "- Target: Adsorption energy in eV\n",
    "- metadata: data class (int), anomaly class(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from fairchem.core.datasets import LmdbDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process all .lmdb files and generate df\n",
    "\n",
    "Keep the same directory structure as the folder with the .lmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = '10k'  # 10k, 100k, or all\n",
    "ROOT_DF = f'../data/is2res_train_val_test_dfs/{SPLIT}'\n",
    "ROOT_LMDB = f'../data/is2res_train_val_test_lmdbs/data/is2re/{SPLIT}'\n",
    "OC20_INFO = \"../data/oc20_data_mapping.pkl\"\n",
    "ADSORBATE_DB = \"../data/adsorbate_db_2021apr28.pkl\"\n",
    "SLICES_MAP = \"../data/bulk/mapping_mpid_to_slice.pkl\"\n",
    "ADSORBATE_DICT = \"../data/adsorbate_string_dict.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adsorbate_db = pd.read_pickle(ADSORBATE_DB)\n",
    "oc20_map = pd.read_pickle(OC20_INFO)\n",
    "slices_map = pd.read_pickle(SLICES_MAP)\n",
    "adsorbate_dict = pd.read_pickle(ADSORBATE_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_energy_adsorbate(c=0, h=0, n=0, o=0):\n",
    "    Ec, Eh, En, Eo = -7.282, -3.477, -8.083, -7.204\n",
    "    return c * Ec + h * Eh + n * En + o * Eo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in os.listdir(ROOT_DF):\n",
    "    print(dataset)\n",
    "    lmdb_path = f'{ROOT_LMDB}/{dataset}/data.lmdb'\n",
    "    df_path = f'{ROOT_DF}/{dataset}/data.parquet'\n",
    "    db = LmdbDataset({'src': lmdb_path})\n",
    "\n",
    "    print(f'Loaded {lmdb_path}')\n",
    "\n",
    "    # adsorbate features\n",
    "    ads_symbolss, ads_ids = [], []\n",
    "    nC, nH, nO, nN = [], [], [], []\n",
    "    ads_sizes = []\n",
    "    ads_smiless, ads_inchis, ads_inchikeys = [], [], []\n",
    "    ads_ase_formulas = []\n",
    "    ads_energies_eV = []\n",
    "    # material features\n",
    "    bulk_symbolss, bulk_mpids, bulk_ids = [], [], []\n",
    "    slicess = []\n",
    "    natoms_bulk = []  # Number of atoms in the \"unit\" cell\n",
    "    nelems_bulk = []  # Number of distinct elements (A, AB, ABC material)\n",
    "    Cbulk, Hbulk, Obulk, Nbulk = [], [], [], []\n",
    "    # surface features\n",
    "    hs, ks, ls, hkls = [], [], [], []\n",
    "    # data features\n",
    "    sids, anomalies, classes, eads_eV = [], [], [], []\n",
    "    scaled_eads_eV = []\n",
    "\n",
    "    for data in db:\n",
    "        key = f'random{data.sid}'\n",
    "        info = oc20_map[key]\n",
    "        sids.append(data.sid)\n",
    "        # Adsorbate atom count\n",
    "        C, H, O, N = 0, 0, 0, 0 \n",
    "        for i in range(data.num_nodes):\n",
    "            if data.tags[i] == 2:\n",
    "                Z = data.atomic_numbers[i]\n",
    "                if Z == 6:  # C\n",
    "                    C += 1\n",
    "                elif Z == 1:  # H\n",
    "                    H += 1\n",
    "                elif Z == 7:  # N\n",
    "                    N += 1\n",
    "                elif Z == 8:  # O\n",
    "                    O += 1\n",
    "                else:\n",
    "                    raise Exception(\"Something is wronggg.\")\n",
    "        nC.append(C)\n",
    "        nH.append(H)\n",
    "        nO.append(O)\n",
    "        nN.append(N)\n",
    "        ads_sizes.append(C + H + O + N)\n",
    "        anomalies.append(info['anomaly'])\n",
    "        classes.append(info['class'])\n",
    "        h, k, l = info['miller_index']\n",
    "        hs.append(h)\n",
    "        ks.append(k)\n",
    "        ls.append(l)\n",
    "        hkls.append(str(h) + str(k) + str(l))\n",
    "        bulk_symbolss.append(info['bulk_symbols'])\n",
    "        bulk_mpids.append(info['bulk_mpid'])\n",
    "        bulk_ids.append(info['bulk_id'])\n",
    "        slicess.append(slices_map[info['bulk_mpid']])\n",
    "        ads_energies_eV.append(get_energy_adsorbate(C, H, N, O))\n",
    "        ads_symbolss.append(info['ads_symbols'])\n",
    "        ads_ids.append(info['ads_id'])\n",
    "        if 'test' in dataset:  # Target unavailable\n",
    "            eads_eV.append('N/A')\n",
    "            scaled_eads_eV.append('N/A')\n",
    "        else:\n",
    "            eads_eV.append(data.y_relaxed)\n",
    "            scaled_eads_eV.append(eads_eV[-1] + ads_energies_eV[-1])\n",
    "        counter = 0\n",
    "        elems = set()\n",
    "        for i in slicess[-1].split(\" \"):\n",
    "            if i.isnumeric():\n",
    "                break\n",
    "            counter += 1\n",
    "            elems.add(i)\n",
    "        nelems_bulk.append(len(elems))\n",
    "        natoms_bulk.append(counter)\n",
    "        ads_smiless.append(adsorbate_dict[info['ads_id']][\"smiles\"])\n",
    "        ads_inchis.append(adsorbate_dict[info['ads_id']][\"inchi\"])\n",
    "        ads_inchikeys.append(adsorbate_dict[info['ads_id']][\"inchikey\"])\n",
    "        ads_ase_formulas.append(adsorbate_dict[info['ads_id']][\"ase_formula\"])\n",
    "        Cbulk.append('C' in slicess[-1].split())\n",
    "        Hbulk.append('H' in slicess[-1].split())\n",
    "        Nbulk.append('N' in slicess[-1].split())\n",
    "        Obulk.append('O' in slicess[-1].split())\n",
    "        \n",
    "\n",
    "    print(len(sids), len(natoms_bulk), len(nelems_bulk))\n",
    "\n",
    "    df = pd.DataFrame({'sid': sids,\n",
    "                  'anomaly': anomalies, \n",
    "                  'class': classes, \n",
    "                  'C': nC, \n",
    "                  'H': nH, \n",
    "                  'O': nO, \n",
    "                  'N': nN, \n",
    "                  'ads_size': ads_sizes, \n",
    "                  'ads_symbols': ads_symbolss, \n",
    "                  'ads_id': ads_ids, \n",
    "                  'ads_smiles': ads_smiless, \n",
    "                  'ads_inchi': ads_inchis, \n",
    "                  'ads_inchikeys': ads_inchikeys,\n",
    "                  'ads_ase_formula': ads_ase_formulas,\n",
    "                  'ads_energy_eV': ads_energies_eV, \n",
    "                  'bulk_symbols': bulk_symbolss, \n",
    "                  'bulk_mpid': bulk_mpids, \n",
    "                  'bulk_id': bulk_ids, \n",
    "                  'bulk_nelems': nelems_bulk, \n",
    "                  'bulk_natoms': natoms_bulk,\n",
    "                  'C_in_bulk': Cbulk, \n",
    "                  'H_in_bulk': Hbulk,\n",
    "                  'O_in_bulk': Obulk,\n",
    "                  'N_in_bulk': Nbulk,\n",
    "                  'slices': slicess,\n",
    "                  'h': hs, \n",
    "                  'k': ks, \n",
    "                  'l': ls, \n",
    "                  'hkl': hkls, \n",
    "                  'eads_eV': eads_eV, \n",
    "                  'scaled_eads_eV': scaled_eads_eV})\n",
    "    \n",
    "    df.to_parquet(df_path)\n",
    "    print(f'Saved {df_path}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(df_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add HetSMILES (order1)\n",
    "\n",
    "For both initial state and final state, together with the 'full representation' boolean variable. This variable is True when the SMILES/graph includes all elements of the material, False if not. It could happen for cases where the material consists of multiple elements and the adsorbate is more prone to interact only with a subset of material elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lines2lists(xx: list):\n",
    "    idxs, fris, frfs, his, hfs = [], [], [], [], []\n",
    "    for line in xx:\n",
    "        y = line.replace(\"\\n\", \"\").split(\" \")\n",
    "        idxs.append(y[0])\n",
    "        fris.append(y[1])\n",
    "        frfs.append(y[3])\n",
    "        his.append(y[2])\n",
    "        hfs.append(y[4])\n",
    "    return idxs, fris, his, frfs, hfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = 'all'  # 10k, 100k, or all\n",
    "SET = 'val_ood_both'\n",
    "ORDER = 'o1'  # o1 or o2\n",
    "DF_PATH = f'../data/is2res_train_val_test_dfs/{SPLIT}/{SET}/data.parquet'\n",
    "# SMILES_PATH = f'../data/hetsmiles/{SPLIT}_{ORDER}.txt'\n",
    "SMILES_PATH = f'../data/hetsmiles/both_{ORDER}.txt'\n",
    "df = pd.read_parquet(DF_PATH)\n",
    "df.head()\n",
    "\n",
    "with open(SMILES_PATH, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "print(lines[0])\n",
    "print(len(lines), len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs, fris, his, frfs, hfs = lines2lists(lines)\n",
    "\n",
    "len_his = [len(x) for x in his]\n",
    "len_hfs = [len(x) for x in hfs]\n",
    "\n",
    "print(len(len_his))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hetsmiles_IS_o1'] = his\n",
    "df['hetsmiles_FS_o1'] = hfs\n",
    "df['frh_IS_o1'] = fris\n",
    "df['frh_FS_o1'] = frfs\n",
    "df['len_his_o1'] = len_his\n",
    "df['len_hfs_o1'] = len_hfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(DF_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate adsorbate SMILES/InChI/InChIKey\n",
    "\n",
    "- Should work for both closed-shell and open-shell molecules (CH4, CH3, CH2, CH3O, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adsorbate_dict = {}\n",
    "\n",
    "# for idx, v in adsorbate_db.items():\n",
    "#     y_dict = {}\n",
    "#     v[0]._pbc = np.array([1,1,1])\n",
    "#     atoms = v[0]\n",
    "#     ase.io.write('test.pdb', atoms)\n",
    "#     mol = Chem.rdmolfiles.MolFromPDBFile('test.pdb', sanitize=False, removeHs=True)\n",
    "#     num_bonds = mol.GetNumBonds()\n",
    "#     # https://github.com/IUPAC-InChI/InChI/blob/main/INCHI-1-DOC/InChI_UserGuide.pdf for options\n",
    "#     inchi = Chem.MolToInchi(mol, options='/DoNotAddH')\n",
    "#     inchikey = Chem.MolToInchiKey(mol, options='/DoNotAddH')\n",
    "#     smiles = Chem.MolToSmiles(mol, allHsExplicit=False)\n",
    "#     ase_formula = atoms.get_chemical_formula()\n",
    "#     if smiles == '[HH]':\n",
    "#         smiles = '[H]'\n",
    "#     y_dict['smiles'] = smiles\n",
    "#     y_dict['inchi'] = inchi    \n",
    "#     y_dict['inchikey'] = inchikey\n",
    "#     y_dict['ase_formula'] = ase_formula\n",
    "#     adsorbate_dict[idx] = y_dict\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# with open('adsorbate_string_dict.pkl', 'wb') as fp:\n",
    "#     pickle.dump(adsorbate_dict, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
